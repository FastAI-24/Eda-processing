"""
ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ (Trainer)

K-Fold êµì°¨ ê²€ì¦ê³¼ RMSE í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ëŠ” í•µì‹¬ ëª¨ë“ˆì…ë‹ˆë‹¤.

ë””ìì¸ íŒ¨í„´:
    - Strategy Pattern: BaseModel ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ ëª¨ë¸ êµì²´ ê°€ëŠ¥
    - Template Method: train_with_cv()ê°€ í•™ìŠµ/í‰ê°€ì˜ ì „ì²´ íë¦„ì„ ì œì–´
    - Mediator Pattern: TrainingResultê°€ ê²°ê³¼ë¥¼ ì¤‘ì•™ ì§‘ì•½

ê°œì„  ì‚¬í•­ (v2):
    - TimeSeriesSplit CV ì§€ì› (ê³„ì•½ë…„ì›” ì •ë ¬ ê¸°ë°˜)
    - Fold ë‚´ Target Encoding (CV ëˆ„ìˆ˜ ë°©ì§€)
    - ì‹œê°„ ê¸°ë°˜ Sample Weight (ìµœê·¼ ë°ì´í„° ê°€ì¤‘ì¹˜)

ì‚¬ìš© ì˜ˆ:
    from modeling import Trainer, LightGBMModel, ModelConfig

    config = ModelConfig(n_splits=5, cv_strategy="timeseries")
    trainer = Trainer(config)

    model = LightGBMModel(config)
    result = trainer.train_with_cv(model, X_train, y_train)
    print(result.summary())
"""

from __future__ import annotations

import time
from concurrent.futures import ThreadPoolExecutor

import numpy as np
import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold, TimeSeriesSplit
from tqdm import tqdm

from .base import BaseModel, TrainingResult
from .config import ModelConfig


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Fold ë‚´ Target Encoding ìœ í‹¸ë¦¬í‹° (ì»¬ëŸ¼ë³„ ë³‘ë ¬ ì²˜ë¦¬)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _encode_single_column(
    col: str,
    train_col_str: pd.Series,
    val_col_str: pd.Series,
    test_col_str: pd.Series | None,
    y_train_fold: np.ndarray,
    global_mean: float,
    smoothing: int,
) -> dict[str, pd.Series]:
    """ë‹¨ì¼ ì»¬ëŸ¼ì— ëŒ€í•´ TE + Freq ì¸ì½”ë”©ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤ (ë³‘ë ¬ í˜¸ì¶œìš©)."""
    result: dict[str, pd.Series] = {}

    # Bayesian Smoothed Mean
    tmp = pd.DataFrame({"key": train_col_str, "y": y_train_fold})
    group_stats = tmp.groupby("key")["y"].agg(["mean", "count"])
    smoothed = (
        group_stats["count"] * group_stats["mean"]
        + smoothing * global_mean
    ) / (group_stats["count"] + smoothing)
    encoding_map = smoothed.to_dict()

    te_col = f"te_{col}"
    result[f"train_{te_col}"] = train_col_str.map(encoding_map).fillna(global_mean)
    result[f"val_{te_col}"] = val_col_str.map(encoding_map).fillna(global_mean)
    if test_col_str is not None:
        result[f"test_{te_col}"] = test_col_str.map(encoding_map).fillna(global_mean)

    # ë¹ˆë„ ì¸ì½”ë”©
    freq_col = f"freq_{col}"
    freq_map = train_col_str.value_counts().to_dict()
    result[f"train_{freq_col}"] = train_col_str.map(freq_map).fillna(0).astype("float64")
    result[f"val_{freq_col}"] = val_col_str.map(freq_map).fillna(0).astype("float64")
    if test_col_str is not None:
        result[f"test_{freq_col}"] = test_col_str.map(freq_map).fillna(0).astype("float64")

    return result


def compute_fold_target_encoding(
    X_train_fold: pd.DataFrame,
    y_train_fold: np.ndarray,
    X_val_fold: pd.DataFrame,
    X_test: pd.DataFrame | None,
    te_cols: list[str],
    smoothing: int = 100,
) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame | None]:
    """Fold ë‚´ë¶€ì—ì„œ Bayesian Smoothed Target Encodingì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    í•™ìŠµ foldì—ì„œë§Œ encoding mapì„ ê³„ì‚°í•˜ì—¬ CV ëˆ„ìˆ˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    ê° ëŒ€ìƒ ì»¬ëŸ¼ì— ëŒ€í•´ 2ê°œì”© íŒŒìƒ í”¼ì²˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ì»¬ëŸ¼ë³„ ì¸ì½”ë”©ì€ ThreadPoolExecutorë¡œ ë³‘ë ¬ ì²˜ë¦¬ë©ë‹ˆë‹¤.

    ìƒì„± í”¼ì²˜ (ëŒ€ìƒ ì»¬ëŸ¼ë³„):
        - te_{ì»¬ëŸ¼ëª…}: Bayesian Smoothed Target Encoding ê°’
          (í•´ë‹¹ ë²”ì£¼ì˜ í‰ê·  targetì„ smoothingí•˜ì—¬ ìˆ˜ì¹˜í™”)
        - freq_{ì»¬ëŸ¼ëª…}: ë¹ˆë„ ì¸ì½”ë”© ê°’
          (í•´ë‹¹ ë²”ì£¼ì˜ í•™ìŠµ ë°ì´í„° ë‚´ ê±°ë˜ ê±´ìˆ˜ = ì¸ê¸°ë„ ì§€í‘œ)

    ê¸°ë³¸ ëŒ€ìƒ ì»¬ëŸ¼ (config.target_encode_cols):
        ì•„íŒŒíŠ¸ëª…, ë„ë¡œëª…, ë²ˆì§€, ì‹œêµ°êµ¬, êµ¬, ë™ â†’ ì´ 12ê°œ í”¼ì²˜ ìƒì„±
    """
    X_train_fold = X_train_fold.copy()
    X_val_fold = X_val_fold.copy()
    X_test_out = X_test.copy() if X_test is not None else None

    global_mean = float(np.mean(y_train_fold))

    # ìœ íš¨ ì»¬ëŸ¼ë§Œ í•„í„°ë§
    valid_cols = [c for c in te_cols if c in X_train_fold.columns]

    # ì»¬ëŸ¼ë³„ ë¬¸ìì—´ ë³€í™˜ ë¯¸ë¦¬ ìˆ˜í–‰ (ê³µìœ )
    train_str = {c: X_train_fold[c].astype(str) for c in valid_cols}
    val_str = {c: X_val_fold[c].astype(str) for c in valid_cols}
    test_str = (
        {c: X_test_out[c].astype(str) for c in valid_cols}
        if X_test_out is not None else {}
    )

    # ThreadPoolExecutorë¡œ ì»¬ëŸ¼ë³„ ë³‘ë ¬ ì¸ì½”ë”©
    max_workers = min(len(valid_cols), 6)
    all_results: list[dict[str, pd.Series]] = []

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {
            executor.submit(
                _encode_single_column,
                col,
                train_str[col],
                val_str[col],
                test_str.get(col),
                y_train_fold,
                global_mean,
                smoothing,
            ): col
            for col in valid_cols
        }
        for future in futures:
            all_results.append(future.result())

    # ê²°ê³¼ í•©ì¹˜ê¸°
    for res in all_results:
        for key, series in res.items():
            if key.startswith("train_"):
                col_name = key[len("train_"):]
                X_train_fold[col_name] = series
            elif key.startswith("val_"):
                col_name = key[len("val_"):]
                X_val_fold[col_name] = series
            elif key.startswith("test_") and X_test_out is not None:
                col_name = key[len("test_"):]
                X_test_out[col_name] = series

    return X_train_fold, X_val_fold, X_test_out


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Fold ë‚´ ì‹œê°„-ì§€ì—° í”¼ì²˜ (ì•„íŒŒíŠ¸/ë™/êµ¬ë³„ ê°€ê²© ì¶”ì„¸)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def compute_fold_time_lag_features(
    X_train_fold: pd.DataFrame,
    y_train_fold: np.ndarray,
    X_val_fold: pd.DataFrame,
    X_test: pd.DataFrame | None,
    time_col: str = "ê³„ì•½ë…„ì›”",
    lag_cols: list[str] | None = None,
    recent_months: int = 24,
) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame | None]:
    """Fold í•™ìŠµ ë°ì´í„°ë§Œ ì‚¬ìš©í•˜ì—¬ ì‹œê°„ ê¸°ë°˜ ê°€ê²© ì¶”ì„¸ í”¼ì²˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    CV ëˆ„ìˆ˜ ë°©ì§€: fold í•™ìŠµ ë°ì´í„°ì—ì„œë§Œ í†µê³„ ê³„ì‚° â†’ val/testì— ë§¤í•‘.

    ìƒì„± í”¼ì²˜ (lag_colsë³„):
        - {col}_tx_count: í•´ë‹¹ ë²”ì£¼ì˜ ê±°ë˜ ê±´ìˆ˜
        - {col}_recent_price: ìµœê·¼ Nê°œì›” í‰ê· ê°€ (log space)
        - {col}_price_trend: ê°€ê²© ì¶”ì„¸ (recent/overall - 1)
    """
    if lag_cols is None:
        lag_cols = ["ì•„íŒŒíŠ¸ëª…", "ë™", "êµ¬"]

    if time_col not in X_train_fold.columns:
        return X_train_fold, X_val_fold, X_test.copy() if X_test is not None else None

    X_train_fold = X_train_fold.copy()
    X_val_fold = X_val_fold.copy()
    X_test_out = X_test.copy() if X_test is not None else None

    ym = pd.to_numeric(X_train_fold[time_col], errors="coerce").fillna(0).astype(int)
    max_ym = int(ym.max()) if ym.max() > 0 else 202312
    # YYYYMM â†’ ì´ ê°œì›”ìˆ˜ â†’ Nê°œì›” ì „ â†’ YYYYMM
    y_max, m_max = max_ym // 100, max_ym % 100
    total_months = max(0, y_max * 12 + m_max - recent_months)
    recent_cutoff = (total_months // 12) * 100 + (total_months % 12)

    base_df = pd.DataFrame({
        "target": y_train_fold,
        "ym": ym.values,
    })

    created: list[str] = []

    for col in lag_cols:
        if col not in X_train_fold.columns:
            continue
        base_df["cat"] = X_train_fold[col].astype(str).values

        # ê±°ë˜ ê±´ìˆ˜
        tx_count = base_df.groupby("cat")["target"].count()
        for df_out, df_src in [
            (X_train_fold, X_train_fold),
            (X_val_fold, X_val_fold),
            (X_test_out, X_test) if X_test_out is not None else (None, None),
        ]:
            if df_out is not None and col in df_src.columns:
                df_out[f"{col}_tx_count"] = df_src[col].astype(str).map(tx_count).fillna(0).astype("float64")
        created.append(f"{col}_tx_count")

        # ì „ì²´ í‰ê· ê°€
        full_mean = base_df.groupby("cat")["target"].mean()

        # ìµœê·¼ Nê°œì›” í‰ê· ê°€
        recent_mask = base_df["ym"] >= recent_cutoff
        if recent_mask.sum() > 0:
            recent_mean = base_df.loc[recent_mask].groupby("cat")["target"].mean()
            trend = (recent_mean / full_mean).reindex(full_mean.index).fillna(0.0) - 1.0

            for df_out, df_src in [
                (X_train_fold, X_train_fold),
                (X_val_fold, X_val_fold),
                (X_test_out, X_test) if X_test_out is not None else (None, None),
            ]:
                if df_out is not None and col in df_src.columns:
                    df_out[f"{col}_recent_price"] = df_src[col].astype(str).map(recent_mean).fillna(0)
                    df_out[f"{col}_price_trend"] = df_src[col].astype(str).map(trend).fillna(0)
            created.extend([f"{col}_recent_price", f"{col}_price_trend"])

    return X_train_fold, X_val_fold, X_test_out


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Sample Weight ìœ í‹¸ë¦¬í‹°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def compute_sample_weight(
    X_fold: pd.DataFrame,
    decay: float = 0.05,
) -> np.ndarray | None:
    """ì‹œê°„ ê¸°ë°˜ ì§€ìˆ˜ ê°ì‡  ìƒ˜í”Œ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

    ìµœê·¼ ë°ì´í„°ì— ë” í° ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ ì‹œì¥ íŠ¸ë Œë“œ ë³€í™”ë¥¼ ë°˜ì˜í•©ë‹ˆë‹¤.

    Args:
        X_fold: í•™ìŠµ fold ë°ì´í„° (ê³„ì•½ë…„ ì»¬ëŸ¼ í•„ìš”)
        decay: ì§€ìˆ˜ ê°ì‡  ê³„ìˆ˜ (í´ìˆ˜ë¡ ìµœê·¼ ê°€ì¤‘ì¹˜â†‘)

    Returns:
        sample_weight ë°°ì—´ ë˜ëŠ” None (ê³„ì•½ë…„ ì»¬ëŸ¼ ì—†ëŠ” ê²½ìš°)
    """
    year_col = None
    for c in ["ê³„ì•½ë…„", "ê³„ì•½ë…„ì›”"]:
        if c in X_fold.columns:
            year_col = c
            break

    if year_col is None:
        return None

    if year_col == "ê³„ì•½ë…„ì›”":
        years = pd.to_numeric(X_fold[year_col], errors="coerce") // 100
    else:
        years = pd.to_numeric(X_fold[year_col], errors="coerce")

    years = years.fillna(years.median())
    max_year = years.max()
    weights = np.exp(-decay * (max_year - years.values).astype(float))

    # ì •ê·œí™” (í‰ê·  1.0)
    weights = weights / weights.mean()
    return weights


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Trainer
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class Trainer:
    """K-Fold êµì°¨ ê²€ì¦ ê¸°ë°˜ ëª¨ë¸ í•™ìŠµ ë° RMSE í‰ê°€ê¸°.

    Template Method íŒ¨í„´ìœ¼ë¡œ í•™ìŠµ íë¦„ì„ ì œì–´í•©ë‹ˆë‹¤:
        1. ë°ì´í„° ì¤€ë¹„ (íƒ€ê²Ÿ ë³€í™˜)
        2. K-Fold / TimeSeriesSplit ë¶„í• 
        3. ê° Foldì—ì„œ (ì„ íƒì ) Target Encoding
        4. ì‹œê°„ ê¸°ë°˜ Sample Weight ì ìš©
        5. ëª¨ë¸ í•™ìŠµ/ê²€ì¦
        6. RMSE ê³„ì‚° ë° ì§‘ê³„
        7. OOF ì˜ˆì¸¡ ë° í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ìƒì„±
    """

    def __init__(self, config: ModelConfig | None = None) -> None:
        self._config = config or ModelConfig()

    def _detect_categorical_features(self, X: pd.DataFrame) -> list[str]:
        """ë²”ì£¼í˜• í”¼ì²˜ë¥¼ ìë™ ê°ì§€í•©ë‹ˆë‹¤."""
        if self._config.categorical_features is not None:
            return [c for c in self._config.categorical_features if c in X.columns]

        cat_cols = []
        for col in X.columns:
            dtype_str = str(X[col].dtype)
            if (
                X[col].dtype == object
                or dtype_str in ("category", "string", "str", "object")
                or pd.api.types.is_string_dtype(X[col])
            ):
                cat_cols.append(col)
        return cat_cols

    def _create_cv_splitter(self, X: pd.DataFrame):
        """CV ì „ëµì— ë”°ë¼ splitterë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        cfg = self._config

        if cfg.cv_strategy == "timeseries":
            # ê³„ì•½ë…„ì›”ë¡œ ì •ë ¬ëœ ì¸ë±ìŠ¤ ê¸°ë°˜ TimeSeriesSplit
            return TimeSeriesSplit(n_splits=cfg.n_splits)
        else:
            return KFold(
                n_splits=cfg.n_splits,
                shuffle=True,
                random_state=cfg.random_state,
            )

    def train_with_cv(
        self,
        model_factory: type[BaseModel] | BaseModel,
        X: pd.DataFrame,
        y: pd.Series | np.ndarray,
        X_test: pd.DataFrame | None = None,
    ) -> TrainingResult:
        """K-Fold êµì°¨ ê²€ì¦ìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  RMSEë¥¼ í‰ê°€í•©ë‹ˆë‹¤."""
        cfg = self._config
        start_time = time.time()

        # â”€â”€ íƒ€ê²Ÿ ë³€í™˜ â”€â”€
        if cfg.use_log_target:
            y_transformed = np.log1p(y)
            print(f"íƒ€ê²Ÿ ë³€í™˜: log1p (ë²”ìœ„: [{y_transformed.min():.4f}, {y_transformed.max():.4f}])")
        else:
            y_transformed = np.asarray(y, dtype=np.float64)
            print(f"íƒ€ê²Ÿ: ì›ë³¸ ìŠ¤ì¼€ì¼ (ë²”ìœ„: [{y_transformed.min():,.0f}, {y_transformed.max():,.0f}])")

        # â”€â”€ ëª¨ë¸ ì •ë³´ â”€â”€
        if isinstance(model_factory, type):
            sample_model = model_factory(cfg)
            model_name = sample_model.name
        else:
            model_name = model_factory.name

        # â”€â”€ ë²”ì£¼í˜• í”¼ì²˜ ê°ì§€ â”€â”€
        cat_features = self._detect_categorical_features(X)
        print(f"ë²”ì£¼í˜• í”¼ì²˜: {len(cat_features)}ê°œ")

        # â”€â”€ TimeSeriesSplitì¸ ê²½ìš° ì •ë ¬ â”€â”€
        sort_col = None
        if cfg.cv_strategy == "timeseries":
            for c in ["ê³„ì•½ë…„ì›”", "ê³„ì•½ì¼ì"]:
                if c in X.columns:
                    sort_col = c
                    break
            if sort_col:
                sort_idx = X[sort_col].argsort()
                X = X.iloc[sort_idx].reset_index(drop=True)
                if isinstance(y_transformed, np.ndarray):
                    y_transformed = y_transformed[sort_idx]
                else:
                    y_transformed = y_transformed.iloc[sort_idx].reset_index(drop=True)
                if isinstance(y, np.ndarray):
                    y = y[sort_idx]
                else:
                    y = y.iloc[sort_idx].reset_index(drop=True)
                print(f"TimeSeriesSplit: '{sort_col}' ê¸°ì¤€ ì •ë ¬ ì™„ë£Œ")

        # â”€â”€ CV Splitter â”€â”€
        cv = self._create_cv_splitter(X)

        oof_preds = np.zeros(len(X))
        test_preds = np.zeros(len(X_test)) if X_test is not None else None
        fold_scores: list[float] = []
        all_importances: list[pd.DataFrame] = []
        trained_models: list = []

        # â”€â”€ ìš”ì•½ ì •ë³´ ì¶œë ¥ â”€â”€
        info_parts = [
            f"CV={cfg.cv_strategy}",
            f"K={cfg.n_splits}",
            f"ë°ì´í„°={X.shape}",
        ]
        if cfg.use_sample_weight:
            info_parts.append(f"SW(decay={cfg.sample_weight_decay})")
        if cfg.use_fold_target_encoding:
            info_parts.append(f"TE({len(cfg.target_encode_cols)}cols)")
        if getattr(cfg, "use_fold_time_lag", False) and cfg.time_lag_cols:
            info_parts.append(f"TL({len(cfg.time_lag_cols)}cols)")
        print(f"\n  âš™ {model_name} | {' | '.join(info_parts)}")

        # â”€â”€ tqdm Fold ì§„í–‰ ë°” â”€â”€
        fold_bar = tqdm(
            enumerate(cv.split(X), 1),
            total=cfg.n_splits,
            desc=f"  ğŸ”„ {model_name}",
            bar_format="  {l_bar}{bar:30}{r_bar}",
            ncols=100,
        )

        for fold_idx, (train_idx, val_idx) in fold_bar:
            fold_start = time.time()

            X_train_fold = X.iloc[train_idx].copy()
            y_train_fold = (
                y_transformed[train_idx]
                if isinstance(y_transformed, np.ndarray)
                else y_transformed.iloc[train_idx]
            )
            X_val_fold = X.iloc[val_idx].copy()
            y_val_fold = (
                y_transformed[val_idx]
                if isinstance(y_transformed, np.ndarray)
                else y_transformed.iloc[val_idx]
            )

            fold_bar.set_postfix_str(
                f"Fold {fold_idx} | í•™ìŠµ:{len(train_idx):,} ê²€ì¦:{len(val_idx):,}"
            )

            # â”€â”€ Fold ë‚´ Target Encoding â”€â”€
            X_test_fold = None
            if cfg.use_fold_target_encoding and cfg.target_encode_cols:
                y_train_np = (
                    y_train_fold
                    if isinstance(y_train_fold, np.ndarray)
                    else y_train_fold.values
                )
                X_train_fold, X_val_fold, X_test_fold = compute_fold_target_encoding(
                    X_train_fold,
                    y_train_np,
                    X_val_fold,
                    X_test,
                    cfg.target_encode_cols,
                    cfg.target_encode_smoothing,
                )
                if fold_idx == 1:
                    te_cols_added = [
                        c for c in X_train_fold.columns
                        if c.startswith("te_") or c.startswith("freq_")
                    ]
                    tqdm.write(f"    TE í”¼ì²˜: {len(te_cols_added)}ê°œ ìƒì„±")

            # â”€â”€ Fold ë‚´ ì‹œê°„-ì§€ì—° í”¼ì²˜ â”€â”€
            if getattr(cfg, "use_fold_time_lag", False) and cfg.time_lag_cols:
                y_train_np = (
                    y_train_fold
                    if isinstance(y_train_fold, np.ndarray)
                    else y_train_fold.values
                )
                X_test_for_tl = X_test_fold if X_test_fold is not None else X_test
                X_train_fold, X_val_fold, X_test_fold = compute_fold_time_lag_features(
                    X_train_fold,
                    y_train_np,
                    X_val_fold,
                    X_test_for_tl,
                    time_col="ê³„ì•½ë…„ì›”",
                    lag_cols=cfg.time_lag_cols,
                    recent_months=getattr(cfg, "time_lag_recent_months", 24),
                )
                if fold_idx == 1:
                    tqdm.write(f"    ì‹œê°„-ì§€ì—° í”¼ì²˜: {cfg.time_lag_cols}")

            # â”€â”€ Sample Weight â”€â”€
            weights = None
            if cfg.use_sample_weight:
                weights = compute_sample_weight(X_train_fold, cfg.sample_weight_decay)

            # â”€â”€ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± â”€â”€
            if isinstance(model_factory, type):
                model = model_factory(cfg)
            else:
                model = type(model_factory)(cfg)

            # â”€â”€ í•™ìŠµ â”€â”€
            model.train(
                X_train_fold,
                y_train_fold,
                X_val_fold,
                y_val_fold,
                categorical_features=cat_features,
                sample_weight=weights,
            )

            # â”€â”€ ê²€ì¦ ì˜ˆì¸¡ ë° RMSE â”€â”€
            val_pred = model.predict(X_val_fold)
            rmse = np.sqrt(mean_squared_error(y_val_fold, val_pred))
            fold_scores.append(rmse)

            # â”€â”€ OOF ì˜ˆì¸¡ ì €ì¥ â”€â”€
            oof_preds[val_idx] = val_pred

            # â”€â”€ í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ëˆ„ì  â”€â”€
            if X_test is not None and test_preds is not None:
                X_test_for_pred = X_test_fold if X_test_fold is not None else X_test
                test_preds += model.predict(X_test_for_pred) / cfg.n_splits

            # â”€â”€ í”¼ì²˜ ì¤‘ìš”ë„ â”€â”€
            imp = model.get_feature_importance()
            if imp is not None:
                imp["fold"] = fold_idx
                all_importances.append(imp)

            trained_models.append(model)

            fold_elapsed = time.time() - fold_start
            avg_rmse = np.mean(fold_scores)
            fold_bar.set_postfix_str(
                f"Fold {fold_idx} RMSE={rmse:.6f} | í‰ê· ={avg_rmse:.6f} | {fold_elapsed:.0f}s"
            )

        # â”€â”€ ìµœì¢… ê²°ê³¼ ì§‘ê³„ â”€â”€
        mean_rmse = np.mean(fold_scores)
        std_rmse = np.std(fold_scores)
        total_elapsed = time.time() - start_time

        # ì „ì²´ OOF RMSE
        oof_rmse = np.sqrt(mean_squared_error(y_transformed, oof_preds))

        tqdm.write(f"\n  âœ… {model_name} ì™„ë£Œ")
        tqdm.write(f"     Foldë³„ : {[f'{s:.6f}' for s in fold_scores]}")
        tqdm.write(f"     í‰ê·    : {mean_rmse:.6f} (Â±{std_rmse:.6f})")
        tqdm.write(f"     OOF    : {oof_rmse:.6f}")
        tqdm.write(f"     ì‹œê°„   : {total_elapsed:.1f}ì´ˆ ({total_elapsed / 60:.1f}ë¶„)")

        # í”¼ì²˜ ì¤‘ìš”ë„ ì§‘ê³„
        feature_importances = None
        if all_importances:
            combined = pd.concat(all_importances, ignore_index=True)
            feature_importances = (
                combined.groupby("feature")["importance"]
                .mean()
                .reset_index()
                .sort_values("importance", ascending=False)
                .reset_index(drop=True)
            )

        return TrainingResult(
            model_name=model_name,
            fold_scores=fold_scores,
            mean_rmse=mean_rmse,
            std_rmse=std_rmse,
            oof_predictions=oof_preds,
            test_predictions=test_preds,
            feature_importances=feature_importances,
            trained_models=trained_models,
        )
