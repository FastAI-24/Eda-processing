"""
ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ (Trainer)

K-Fold êµì°¨ ê²€ì¦ê³¼ RMSE í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ëŠ” í•µì‹¬ ëª¨ë“ˆì…ë‹ˆë‹¤.

ë””ìì¸ íŒ¨í„´:
    - Strategy Pattern: BaseModel ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ ëª¨ë¸ êµì²´ ê°€ëŠ¥
    - Template Method: train_with_cv()ê°€ í•™ìŠµ/í‰ê°€ì˜ ì „ì²´ íë¦„ì„ ì œì–´
    - Mediator Pattern: TrainingResultê°€ ê²°ê³¼ë¥¼ ì¤‘ì•™ ì§‘ì•½

ê°œì„  ì‚¬í•­ (v2):
    - TimeSeriesSplit CV ì§€ì› (ê³„ì•½ë…„ì›” ì •ë ¬ ê¸°ë°˜)
    - Fold ë‚´ Target Encoding (CV ëˆ„ìˆ˜ ë°©ì§€)
    - ì‹œê°„ ê¸°ë°˜ Sample Weight (ìµœê·¼ ë°ì´í„° ê°€ì¤‘ì¹˜)

ì‚¬ìš© ì˜ˆ:
    from modeling import Trainer, LightGBMModel, ModelConfig

    config = ModelConfig(n_splits=5, cv_strategy="timeseries")
    trainer = Trainer(config)

    model = LightGBMModel(config)
    result = trainer.train_with_cv(model, X_train, y_train)
    print(result.summary())
"""

from __future__ import annotations

import time

import numpy as np
import pandas as pd
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold, TimeSeriesSplit
from tqdm import tqdm

from .base import BaseModel, TrainingResult
from .config import ModelConfig


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Fold ë‚´ Target Encoding ìœ í‹¸ë¦¬í‹°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def compute_fold_target_encoding(
    X_train_fold: pd.DataFrame,
    y_train_fold: np.ndarray,
    X_val_fold: pd.DataFrame,
    X_test: pd.DataFrame | None,
    te_cols: list[str],
    smoothing: int = 100,
) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame | None]:
    """Fold ë‚´ë¶€ì—ì„œ Bayesian Smoothed Target Encodingì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    í•™ìŠµ foldì—ì„œë§Œ encoding mapì„ ê³„ì‚°í•˜ì—¬ CV ëˆ„ìˆ˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    X_train_fold = X_train_fold.copy()
    X_val_fold = X_val_fold.copy()
    X_test_out = X_test.copy() if X_test is not None else None

    global_mean = float(np.mean(y_train_fold))

    for col in te_cols:
        if col not in X_train_fold.columns:
            continue

        # ê·¸ë£¹ë³„ í†µê³„ (train foldë§Œ ì‚¬ìš©)
        tmp = pd.DataFrame({
            "key": X_train_fold[col].astype(str),
            "y": y_train_fold,
        })
        group_stats = tmp.groupby("key")["y"].agg(["mean", "count"])

        # Bayesian Smoothed Mean
        smoothed = (
            group_stats["count"] * group_stats["mean"]
            + smoothing * global_mean
        ) / (group_stats["count"] + smoothing)
        encoding_map = smoothed.to_dict()

        # ì ìš©
        te_col = f"te_{col}"
        X_train_fold[te_col] = (
            X_train_fold[col].astype(str).map(encoding_map).fillna(global_mean)
        )
        X_val_fold[te_col] = (
            X_val_fold[col].astype(str).map(encoding_map).fillna(global_mean)
        )
        if X_test_out is not None:
            X_test_out[te_col] = (
                X_test_out[col].astype(str).map(encoding_map).fillna(global_mean)
            )

        # ë¹ˆë„ ì¸ì½”ë”©
        freq_col = f"freq_{col}"
        freq_map = X_train_fold[col].astype(str).value_counts().to_dict()
        X_train_fold[freq_col] = (
            X_train_fold[col].astype(str).map(freq_map).fillna(0).astype("float64")
        )
        X_val_fold[freq_col] = (
            X_val_fold[col].astype(str).map(freq_map).fillna(0).astype("float64")
        )
        if X_test_out is not None:
            X_test_out[freq_col] = (
                X_test_out[col].astype(str).map(freq_map).fillna(0).astype("float64")
            )

    return X_train_fold, X_val_fold, X_test_out


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Sample Weight ìœ í‹¸ë¦¬í‹°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def compute_sample_weight(
    X_fold: pd.DataFrame,
    decay: float = 0.05,
) -> np.ndarray | None:
    """ì‹œê°„ ê¸°ë°˜ ì§€ìˆ˜ ê°ì‡  ìƒ˜í”Œ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

    ìµœê·¼ ë°ì´í„°ì— ë” í° ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ì—¬ ì‹œì¥ íŠ¸ë Œë“œ ë³€í™”ë¥¼ ë°˜ì˜í•©ë‹ˆë‹¤.

    Args:
        X_fold: í•™ìŠµ fold ë°ì´í„° (ê³„ì•½ë…„ ì»¬ëŸ¼ í•„ìš”)
        decay: ì§€ìˆ˜ ê°ì‡  ê³„ìˆ˜ (í´ìˆ˜ë¡ ìµœê·¼ ê°€ì¤‘ì¹˜â†‘)

    Returns:
        sample_weight ë°°ì—´ ë˜ëŠ” None (ê³„ì•½ë…„ ì»¬ëŸ¼ ì—†ëŠ” ê²½ìš°)
    """
    year_col = None
    for c in ["ê³„ì•½ë…„", "ê³„ì•½ë…„ì›”"]:
        if c in X_fold.columns:
            year_col = c
            break

    if year_col is None:
        return None

    if year_col == "ê³„ì•½ë…„ì›”":
        years = pd.to_numeric(X_fold[year_col], errors="coerce") // 100
    else:
        years = pd.to_numeric(X_fold[year_col], errors="coerce")

    years = years.fillna(years.median())
    max_year = years.max()
    weights = np.exp(-decay * (max_year - years.values).astype(float))

    # ì •ê·œí™” (í‰ê·  1.0)
    weights = weights / weights.mean()
    return weights


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Trainer
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class Trainer:
    """K-Fold êµì°¨ ê²€ì¦ ê¸°ë°˜ ëª¨ë¸ í•™ìŠµ ë° RMSE í‰ê°€ê¸°.

    Template Method íŒ¨í„´ìœ¼ë¡œ í•™ìŠµ íë¦„ì„ ì œì–´í•©ë‹ˆë‹¤:
        1. ë°ì´í„° ì¤€ë¹„ (íƒ€ê²Ÿ ë³€í™˜)
        2. K-Fold / TimeSeriesSplit ë¶„í• 
        3. ê° Foldì—ì„œ (ì„ íƒì ) Target Encoding
        4. ì‹œê°„ ê¸°ë°˜ Sample Weight ì ìš©
        5. ëª¨ë¸ í•™ìŠµ/ê²€ì¦
        6. RMSE ê³„ì‚° ë° ì§‘ê³„
        7. OOF ì˜ˆì¸¡ ë° í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ìƒì„±
    """

    def __init__(self, config: ModelConfig | None = None) -> None:
        self._config = config or ModelConfig()

    def _detect_categorical_features(self, X: pd.DataFrame) -> list[str]:
        """ë²”ì£¼í˜• í”¼ì²˜ë¥¼ ìë™ ê°ì§€í•©ë‹ˆë‹¤."""
        if self._config.categorical_features is not None:
            return [c for c in self._config.categorical_features if c in X.columns]

        cat_cols = []
        for col in X.columns:
            dtype_str = str(X[col].dtype)
            if (
                X[col].dtype == object
                or dtype_str in ("category", "string", "str", "object")
                or pd.api.types.is_string_dtype(X[col])
            ):
                cat_cols.append(col)
        return cat_cols

    def _create_cv_splitter(self, X: pd.DataFrame):
        """CV ì „ëµì— ë”°ë¼ splitterë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        cfg = self._config

        if cfg.cv_strategy == "timeseries":
            # ê³„ì•½ë…„ì›”ë¡œ ì •ë ¬ëœ ì¸ë±ìŠ¤ ê¸°ë°˜ TimeSeriesSplit
            return TimeSeriesSplit(n_splits=cfg.n_splits)
        else:
            return KFold(
                n_splits=cfg.n_splits,
                shuffle=True,
                random_state=cfg.random_state,
            )

    def train_with_cv(
        self,
        model_factory: type[BaseModel] | BaseModel,
        X: pd.DataFrame,
        y: pd.Series | np.ndarray,
        X_test: pd.DataFrame | None = None,
    ) -> TrainingResult:
        """K-Fold êµì°¨ ê²€ì¦ìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  RMSEë¥¼ í‰ê°€í•©ë‹ˆë‹¤."""
        cfg = self._config
        start_time = time.time()

        # â”€â”€ íƒ€ê²Ÿ ë³€í™˜ â”€â”€
        if cfg.use_log_target:
            y_transformed = np.log1p(y)
            print(f"íƒ€ê²Ÿ ë³€í™˜: log1p (ë²”ìœ„: [{y_transformed.min():.4f}, {y_transformed.max():.4f}])")
        else:
            y_transformed = np.asarray(y, dtype=np.float64)
            print(f"íƒ€ê²Ÿ: ì›ë³¸ ìŠ¤ì¼€ì¼ (ë²”ìœ„: [{y_transformed.min():,.0f}, {y_transformed.max():,.0f}])")

        # â”€â”€ ëª¨ë¸ ì •ë³´ â”€â”€
        if isinstance(model_factory, type):
            sample_model = model_factory(cfg)
            model_name = sample_model.name
        else:
            model_name = model_factory.name

        # â”€â”€ ë²”ì£¼í˜• í”¼ì²˜ ê°ì§€ â”€â”€
        cat_features = self._detect_categorical_features(X)
        print(f"ë²”ì£¼í˜• í”¼ì²˜: {len(cat_features)}ê°œ")

        # â”€â”€ TimeSeriesSplitì¸ ê²½ìš° ì •ë ¬ â”€â”€
        sort_col = None
        if cfg.cv_strategy == "timeseries":
            for c in ["ê³„ì•½ë…„ì›”", "ê³„ì•½ì¼ì"]:
                if c in X.columns:
                    sort_col = c
                    break
            if sort_col:
                sort_idx = X[sort_col].argsort()
                X = X.iloc[sort_idx].reset_index(drop=True)
                if isinstance(y_transformed, np.ndarray):
                    y_transformed = y_transformed[sort_idx]
                else:
                    y_transformed = y_transformed.iloc[sort_idx].reset_index(drop=True)
                if isinstance(y, np.ndarray):
                    y = y[sort_idx]
                else:
                    y = y.iloc[sort_idx].reset_index(drop=True)
                print(f"TimeSeriesSplit: '{sort_col}' ê¸°ì¤€ ì •ë ¬ ì™„ë£Œ")

        # â”€â”€ CV Splitter â”€â”€
        cv = self._create_cv_splitter(X)

        oof_preds = np.zeros(len(X))
        test_preds = np.zeros(len(X_test)) if X_test is not None else None
        fold_scores: list[float] = []
        all_importances: list[pd.DataFrame] = []
        trained_models: list = []

        # â”€â”€ ìš”ì•½ ì •ë³´ ì¶œë ¥ â”€â”€
        info_parts = [
            f"CV={cfg.cv_strategy}",
            f"K={cfg.n_splits}",
            f"ë°ì´í„°={X.shape}",
        ]
        if cfg.use_sample_weight:
            info_parts.append(f"SW(decay={cfg.sample_weight_decay})")
        if cfg.use_fold_target_encoding:
            info_parts.append(f"TE({len(cfg.target_encode_cols)}cols)")
        print(f"\n  âš™ {model_name} | {' | '.join(info_parts)}")

        # â”€â”€ tqdm Fold ì§„í–‰ ë°” â”€â”€
        fold_bar = tqdm(
            enumerate(cv.split(X), 1),
            total=cfg.n_splits,
            desc=f"  ğŸ”„ {model_name}",
            bar_format="  {l_bar}{bar:30}{r_bar}",
            ncols=100,
        )

        for fold_idx, (train_idx, val_idx) in fold_bar:
            fold_start = time.time()

            X_train_fold = X.iloc[train_idx].copy()
            y_train_fold = (
                y_transformed[train_idx]
                if isinstance(y_transformed, np.ndarray)
                else y_transformed.iloc[train_idx]
            )
            X_val_fold = X.iloc[val_idx].copy()
            y_val_fold = (
                y_transformed[val_idx]
                if isinstance(y_transformed, np.ndarray)
                else y_transformed.iloc[val_idx]
            )

            fold_bar.set_postfix_str(
                f"Fold {fold_idx} | í•™ìŠµ:{len(train_idx):,} ê²€ì¦:{len(val_idx):,}"
            )

            # â”€â”€ Fold ë‚´ Target Encoding â”€â”€
            X_test_fold = None
            if cfg.use_fold_target_encoding and cfg.target_encode_cols:
                y_train_np = (
                    y_train_fold
                    if isinstance(y_train_fold, np.ndarray)
                    else y_train_fold.values
                )
                X_train_fold, X_val_fold, X_test_fold = compute_fold_target_encoding(
                    X_train_fold,
                    y_train_np,
                    X_val_fold,
                    X_test,
                    cfg.target_encode_cols,
                    cfg.target_encode_smoothing,
                )
                if fold_idx == 1:
                    te_cols_added = [
                        c for c in X_train_fold.columns
                        if c.startswith("te_") or c.startswith("freq_")
                    ]
                    tqdm.write(f"    TE í”¼ì²˜: {len(te_cols_added)}ê°œ ìƒì„±")

            # â”€â”€ Sample Weight â”€â”€
            weights = None
            if cfg.use_sample_weight:
                weights = compute_sample_weight(X_train_fold, cfg.sample_weight_decay)

            # â”€â”€ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± â”€â”€
            if isinstance(model_factory, type):
                model = model_factory(cfg)
            else:
                model = type(model_factory)(cfg)

            # â”€â”€ í•™ìŠµ â”€â”€
            model.train(
                X_train_fold,
                y_train_fold,
                X_val_fold,
                y_val_fold,
                categorical_features=cat_features,
                sample_weight=weights,
            )

            # â”€â”€ ê²€ì¦ ì˜ˆì¸¡ ë° RMSE â”€â”€
            val_pred = model.predict(X_val_fold)
            rmse = np.sqrt(mean_squared_error(y_val_fold, val_pred))
            fold_scores.append(rmse)

            # â”€â”€ OOF ì˜ˆì¸¡ ì €ì¥ â”€â”€
            oof_preds[val_idx] = val_pred

            # â”€â”€ í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ëˆ„ì  â”€â”€
            if X_test is not None and test_preds is not None:
                X_test_for_pred = X_test_fold if X_test_fold is not None else X_test
                test_preds += model.predict(X_test_for_pred) / cfg.n_splits

            # â”€â”€ í”¼ì²˜ ì¤‘ìš”ë„ â”€â”€
            imp = model.get_feature_importance()
            if imp is not None:
                imp["fold"] = fold_idx
                all_importances.append(imp)

            trained_models.append(model)

            fold_elapsed = time.time() - fold_start
            avg_rmse = np.mean(fold_scores)
            fold_bar.set_postfix_str(
                f"Fold {fold_idx} RMSE={rmse:.6f} | í‰ê· ={avg_rmse:.6f} | {fold_elapsed:.0f}s"
            )

        # â”€â”€ ìµœì¢… ê²°ê³¼ ì§‘ê³„ â”€â”€
        mean_rmse = np.mean(fold_scores)
        std_rmse = np.std(fold_scores)
        total_elapsed = time.time() - start_time

        # ì „ì²´ OOF RMSE
        oof_rmse = np.sqrt(mean_squared_error(y_transformed, oof_preds))

        tqdm.write(f"\n  âœ… {model_name} ì™„ë£Œ")
        tqdm.write(f"     Foldë³„ : {[f'{s:.6f}' for s in fold_scores]}")
        tqdm.write(f"     í‰ê·    : {mean_rmse:.6f} (Â±{std_rmse:.6f})")
        tqdm.write(f"     OOF    : {oof_rmse:.6f}")
        tqdm.write(f"     ì‹œê°„   : {total_elapsed:.1f}ì´ˆ ({total_elapsed / 60:.1f}ë¶„)")

        # í”¼ì²˜ ì¤‘ìš”ë„ ì§‘ê³„
        feature_importances = None
        if all_importances:
            combined = pd.concat(all_importances, ignore_index=True)
            feature_importances = (
                combined.groupby("feature")["importance"]
                .mean()
                .reset_index()
                .sort_values("importance", ascending=False)
                .reset_index(drop=True)
            )

        return TrainingResult(
            model_name=model_name,
            fold_scores=fold_scores,
            mean_rmse=mean_rmse,
            std_rmse=std_rmse,
            oof_predictions=oof_preds,
            test_predictions=test_preds,
            feature_importances=feature_importances,
            trained_models=trained_models,
        )
