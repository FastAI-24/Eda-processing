{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 베이스라인 모델: LightGBM (최종 제출용)\n",
                "\n",
                "이 노트북은 전처리가 완벽하게 완료된 데이터(train_final.csv, test_final.csv)를 사용하여,\n",
                "가장 기본적인 LightGBM 모델을 학습하고 리더보드 제출 파일을 생성합니다.\n",
                "\n",
                "### 목표\n",
                "1. 전처리된 데이터 로드 및 품질 확인 (행 개수 검증)\n",
                "2. LightGBM 모델 학습 (기본 하이퍼파라미터 사용)\n",
                "3. 검증 데이터(Validation)에 대한 RMSE 평가\n",
                "4. 정수형(Integer) 예측값이 담긴 제출 파일 생성"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import os\n",
                "import lightgbm as lgb\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import mean_squared_error\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "# ==========================================\n",
                "# 1. 데이터 경로 자동 탐지\n",
                "# ==========================================\n",
                "# 다양한 실행 환경(로컬, 서버, 코랩 등)에서 유연하게 데이터를 찾기 위해 여러 경로를 리스트로 관리합니다.\n",
                "POSSIBLE_PATHS = [\n",
                "    'data/raw/processed',      # 1순위: run_pipeline_gpu.ipynb가 저장한 기본 경로\n",
                "    '../data/processed',       # 상위 폴더의 processed\n",
                "    'data/processed',          # 현재 폴더 내 processed\n",
                "    './processed',             # 현재 폴더 내 processed (상대 경로)\n",
                "    './'                       # 현재 폴더에 csv가 바로 있는 경우\n",
                "]\n",
                "\n",
                "DATA_DIR = None\n",
                "for path in POSSIBLE_PATHS:\n",
                "    # 해당 경로에 학습 데이터 파일이 실제로 존재하는지 확인합니다.\n",
                "    if os.path.exists(os.path.join(path, 'train_final.csv')):\n",
                "        DATA_DIR = path\n",
                "        break\n",
                "\n",
                "# 만약 모든 경로를 다 뒤져도 파일이 없다면 에러를 발생시켜 실행을 중단합니다.\n",
                "if DATA_DIR is None:\n",
                "    print(f\"현재 작업 경로: {os.getcwd()}\")\n",
                "    raise FileNotFoundError(\"전처리된 데이터 'train_final.csv'를 찾을 수 없습니다. 전처리 파이프라인(run_pipeline_gpu.ipynb)을 먼저 실행해주세요.\")\n",
                "\n",
                "print(f\"데이터 디렉토리 확인됨: {DATA_DIR}\")\n",
                "TRAIN_PATH = os.path.join(DATA_DIR, 'train_final.csv')\n",
                "TEST_PATH = os.path.join(DATA_DIR, 'test_final.csv')\n",
                "\n",
                "# 제출 양식 파일(sample_submission.csv) 찾기\n",
                "# 보통 processed가 아닌 raw 폴더(상위 폴더)에 원본 데이터와 함께 있습니다.\n",
                "RAW_DIR = os.path.dirname(DATA_DIR)\n",
                "SUBMISSION_PATH = os.path.join(RAW_DIR, 'sample_submission.csv')\n",
                "\n",
                "# 만약 바로 위에서 못 찾으면 한 번 더 상위로 가거나 다른 경로를 시도합니다.\n",
                "if not os.path.exists(SUBMISSION_PATH):\n",
                "    # 예: data/raw/processed -> data/raw/sample_submission.csv\n",
                "    SUBMISSION_PATH = os.path.join(RAW_DIR, '../sample_submission.csv')\n",
                "\n",
                "print(f\"학습 데이터: {TRAIN_PATH}\")\n",
                "print(f\"테스트 데이터: {TEST_PATH}\")\n",
                "print(f\"제출 양식: {SUBMISSION_PATH}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 데이터 로드 및 전처리 (모델링용)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# CSV 파일 로드\n",
                "train = pd.read_csv(TRAIN_PATH)\n",
                "test = pd.read_csv(TEST_PATH)\n",
                "\n",
                "print(f\"Train Shape: {train.shape}\")\n",
                "print(f\"Test Shape: {test.shape}\")\n",
                "\n",
                "# [중요] Test 데이터 개수 검증 (9272개)\n",
                "# 전처리 과정에서 테스트 데이터의 행이 삭제되었는지 확인하는 안전장치입니다.\n",
                "if test.shape[0] != 9272:\n",
                "    print(\"경고: Test 데이터 개수가 9272개가 아닙니다! 제출 시 에러가 발생할 수 있습니다.\")\n",
                "else:\n",
                "    print(\"Test 데이터 개수가 정상입니다 (9272개).\")\n",
                "\n",
                "# Target(타겟) 변수 분리 및 로그 변환\n",
                "# 집값과 같은 금액 데이터는 분포의 꼬리가 긴(Skewed) 형태를 띠므로 로그 변환(log1p)을 해주는 것이 학습에 유리합니다.\n",
                "if 'target' in train.columns:\n",
                "    y = np.log1p(train['target'])\n",
                "    X = train.drop(columns=['target'])\n",
                "else:\n",
                "    raise ValueError(\"Train 데이터에 예측해야 할 'target' 컬럼이 없습니다.\")\n",
                "\n",
                "# Test 데이터에는 target 컬럼이 없으므로 그대로 사용합니다.\n",
                "X_test = test.copy()\n",
                "# 혹시라도 실수로 target이 포함되어 있다면 제거합니다.\n",
                "if 'target' in X_test.columns:\n",
                "    X_test.drop(columns=['target'], inplace=True)\n",
                "\n",
                "# 범주형(String/Object) 변수 라벨 인코딩 Process\n",
                "# 머신러닝 모델은 문자열을 이해하지 못하므로 숫자로 변환해주어야 합니다.\n",
                "cat_cols = X.select_dtypes(include=['object']).columns\n",
                "print(f\"범주형 컬럼({len(cat_cols)}개): {list(cat_cols)}\")\n",
                "\n",
                "for col in cat_cols:\n",
                "    le = LabelEncoder()\n",
                "    \n",
                "    # 학습 데이터와 테스트 데이터에 존재하는 모든 범주(Category)를 학습시키기 위해 합칩니다.\n",
                "    # 일부 값은 학습엔 없는데 테스트에만 있거나 그 반대의 경우가 있을 수 있기 때문입니다.\n",
                "    full_data = pd.concat([X[col], X_test[col]], axis=0).astype(str)\n",
                "    le.fit(full_data)\n",
                "    \n",
                "    # 숫자로 변환 적용\n",
                "    X[col] = le.transform(X[col].astype(str))\n",
                "    X_test[col] = le.transform(X_test[col].astype(str))\n",
                "\n",
                "print(\"라벨 인코딩 완료.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. 학습/검증 데이터 분리"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 전체 학습 데이터를 모델 학습용(Training)과 성능 평가용(Validation)으로 8:2 비율로 나눕니다.\n",
                "# random_state=42로 고정하여 실행할 때마다 결과가 달라지지 않도록 합니다.\n",
                "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "print(f\"학습셋 크기: {X_train.shape}\")\n",
                "print(f\"검증셋 크기: {X_val.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. LightGBM 모델 학습 (Baseline)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LightGBM 모델 객체 생성 (기본 설정 사용)\n",
                "# n_jobs=-1: 모든 CPU 코어를 사용하여 학습 속도를 높입니다.\n",
                "model = lgb.LGBMRegressor(random_state=42, n_jobs=-1)\n",
                "\n",
                "print(\"모델 학습 시작...\")\n",
                "# 학습 데이터(X_train)와 정답(y_train)을 넣어 모델을 학습시킵니다.\n",
                "model.fit(X_train, y_train)\n",
                "print(\"학습 완료.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. 평가 (RMSE) 및 시각화"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 검증 데이터(X_val)에 대해 예측을 수행합니다.\n",
                "# 결과는 로그 변환된 값이므로 실제 가격으로 보기 어렵습니다.\n",
                "pred_val_log = model.predict(X_val)\n",
                "\n",
                "# 로그 변환된 값을 다시 원래 스케일(실제 가격)로 복원합니다. (np.expm1 사용)\n",
                "pred_val = np.expm1(pred_val_log)\n",
                "actual_val = np.expm1(y_val)\n",
                "\n",
                "# 성능 지표인 RMSE(평균조화오차)를 계산합니다.\n",
                "rmse = np.sqrt(mean_squared_error(actual_val, pred_val))\n",
                "print(f\"=========================================\")\n",
                "print(f\"Baseline 모델 검증 RMSE: {rmse:,.0f}\")\n",
                "print(f\"=========================================\")\n",
                "\n",
                "# 변수 중요도(Feature Importance) 시각화\n",
                "# 한글 폰트 깨짐 문제를 방지하기 위해 주요 변수명을 영어로 매핑하여 보여줍니다.\n",
                "imp_df = pd.DataFrame({\n",
                "    'Feature': model.feature_name_,\n",
                "    'Importance': model.feature_importances_\n",
                "}).sort_values('Importance', ascending=False).head(20)\n",
                "\n",
                "# 한글 -> 영어 매핑 딕셔너리\n",
                "name_map = {\n",
                "    '좌표X': 'Coord X', \n",
                "    '좌표Y': 'Coord Y', \n",
                "    '건축년도': 'Year Built', \n",
                "    '주차대수': 'Parking Count',\n",
                "    'k-전체세대수': 'Total Households', \n",
                "    'k-연면적': 'Total Floor Area', \n",
                "    'k-주거전용면적': 'Residental Area', \n",
                "    '동': 'Dong', \n",
                "    '구': 'Gu',\n",
                "    '계약일자': 'Contract Date', \n",
                "    '층': 'Floor'\n",
                "}\n",
                "# 딕셔너리에 없는 이름은 원래 이름 그대로 표시합니다.\n",
                "imp_df['Feature_En'] = imp_df['Feature'].map(lambda x: name_map.get(x, x))\n",
                "\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.barplot(data=imp_df, x='Importance', y='Feature_En', palette='viridis')\n",
                "plt.title(\"Feature Importance (Top 20)\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. 제출 파일 생성 (최종)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 테스트 셋(X_test)에 대해 최종 예측을 수행합니다.\n",
                "pred_test_log = model.predict(X_test)\n",
                "pred_test_float = np.expm1(pred_test_log)\n",
                "\n",
                "# [중요] 대회 규칙이나 통상적인 관례에 따라 예측값을 정수(Integer)로 변환합니다. (반올림)\n",
                "pred_test_int = np.round(pred_test_float).astype(int)\n",
                "\n",
                "# 제출 파일 생성 프로세스\n",
                "if os.path.exists(SUBMISSION_PATH):\n",
                "    submission = pd.read_csv(SUBMISSION_PATH)\n",
                "    \n",
                "    # 데이터 개수가 맞는지 마지막으로 한 번 더 확인합니다.\n",
                "    if len(submission) != len(pred_test_int):\n",
                "        print(f\"[치명적 오류] 예측 개수({len(pred_test_int)})와 제출 양식 개수({len(submission)})가 다릅니다.\")\n",
                "    else:\n",
                "        # 예측값을 'target' 컬럼에 덮어씁니다.\n",
                "        submission['target'] = pred_test_int\n",
                "        \n",
                "        # 결과 저장\n",
                "        save_path = os.path.join(DATA_DIR, 'submission_baseline.csv')\n",
                "        submission.to_csv(save_path, index=False)\n",
                "\n",
                "        print(f\"제출 파일 저장 완료: {save_path}\")\n",
                "        print(\"생성된 파일을 다운로드하여 리더보드에 제출하세요!\")\n",
                "        print(submission.head())\n",
                "else:\n",
                "    print(\"sample_submission.csv를 찾지 못했습니다. 경로를 확인해주세요.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}