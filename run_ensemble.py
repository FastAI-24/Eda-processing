"""
ì•™ìƒë¸” í•™ìŠµ ì‹¤í–‰ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸

LightGBM + XGBoost + CatBoost ê°€ì¤‘ í‰ê·  ì•™ìƒë¸”ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:
    cd house-price-prediction
    uv run python run_ensemble.py                    # ì•™ìƒë¸” í•™ìŠµ
    uv run python run_ensemble.py --save-submission  # submission.csv ìƒì„±
    uv run python run_ensemble.py --n-splits 10      # 10-Fold CV
"""

from __future__ import annotations

import argparse
import sys
import time
from pathlib import Path

import numpy as np
import pandas as pd
from tqdm import tqdm

# src/ ë¥¼ ëª¨ë“ˆ ê²€ìƒ‰ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).resolve().parent / "src"))

from modeling.config import ModelConfig  # noqa: E402
from modeling.ensemble import EnsembleTrainer  # noqa: E402


def _load_data(config: ModelConfig) -> tuple[pd.DataFrame, pd.Series, pd.DataFrame]:
    """ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    data_dir = config.data_dir

    x_train_path = data_dir / "X_train_preprocessed.csv"
    y_train_path = data_dir / "y_train_preprocessed.csv"
    x_test_path = data_dir / "X_test_preprocessed.csv"

    for path in [x_train_path, y_train_path, x_test_path]:
        if not path.exists():
            print(f"\n  âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {path}")
            print("  ì „ì²˜ë¦¬ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”: python run.py --skip-eda")
            sys.exit(1)

    files = [
        ("X_train", x_train_path),
        ("y_train", y_train_path),
        ("X_test", x_test_path),
    ]

    data = {}
    for name, path in tqdm(
        files,
        desc="  ğŸ“‚ ë°ì´í„° ë¡œë”©",
        bar_format="  {l_bar}{bar:30}{r_bar}",
        ncols=100,
    ):
        data[name] = pd.read_csv(path)

    X_train = data["X_train"]
    y_train = data["y_train"]["target"]
    X_test = data["X_test"]

    print(f"  X_train: {X_train.shape}  |  y_train: {y_train.shape}  |  X_test: {X_test.shape}")
    return X_train, y_train, X_test


def _save_submission(
    predictions: np.ndarray,
    output_dir: Path,
    use_log_target: bool,
    y_train: np.ndarray | None = None,
) -> None:
    """submission.csvë¥¼ ì €ì¥í•©ë‹ˆë‹¤ (ì„±ëŠ¥ ìµœì í™” Phase 4: ì˜ˆì¸¡ê°’ í´ë¦¬í•‘)."""
    if use_log_target:
        predictions_original = np.expm1(predictions)
    else:
        predictions_original = predictions.copy()

    # ìŒìˆ˜ í´ë¦¬í•‘
    predictions_original = np.maximum(predictions_original, 0)
    # í•™ìŠµ target ë²”ìœ„ ê¸°ë°˜ í´ë¦¬í•‘ (ê·¹ë‹¨ê°’ ë³´ì •)
    if y_train is not None and len(y_train) > 0:
        y_min, y_max = float(y_train.min()), float(y_train.max())
        clip_lo = max(0, y_min * 0.5)
        clip_hi = y_max * 1.5
        predictions_original = np.clip(predictions_original, clip_lo, clip_hi)
    predictions_int = np.round(predictions_original).astype(np.int64)

    # í‰ê°€ ì‹œìŠ¤í…œì´ pred[["ID", "target"]]ë¡œ ì ‘ê·¼í•˜ë¯€ë¡œ ID ì»¬ëŸ¼ í¬í•¨
    submission = pd.DataFrame({
        "ID": range(len(predictions_int)),
        "target": predictions_int,
    })
    submission_path = output_dir / "submission.csv"
    submission.to_csv(submission_path, index=False)

    print(f"\n  ğŸ“„ Submission ì €ì¥: {submission_path}")
    print(f"     Shape: {submission.shape}")
    print(f"     ì˜ˆì¸¡ê°’ ë²”ìœ„: [{predictions_int.min():,} ~ {predictions_int.max():,}] ë§Œì›")
    print(f"     ì˜ˆì¸¡ê°’ í‰ê· : {predictions_int.mean():,.0f} ë§Œì›")


def main(
    n_splits: int = 5,
    save_submission: bool = False,
    models: list[str] | None = None,
    use_stacking: bool = False,
    use_multi_seed: bool = False,
    use_pseudo_labeling: bool = False,
    use_quantile: bool = False,
    use_mlp: bool = False,
    optimized: bool = False,
    cv_strategy: str = "kfold",
    no_tuned_params: bool = False,
) -> None:
    """ì•™ìƒë¸” í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    total_start = time.time()

    config = ModelConfig(n_splits=n_splits)
    config.cv_strategy = cv_strategy
    if models:
        config.ensemble_models = models
    else:
        base = ["lightgbm", "xgboost", "catboost"]
        if use_quantile:
            base.append("lightgbm_quantile")
        if use_mlp:
            base.append("mlp")
        config.ensemble_models = base
    if use_stacking or optimized:
        config.ensemble_strategy = "stacking"
    if use_multi_seed or optimized:
        config.ensemble_use_multi_seed = True
    if optimized:
        config.use_fold_time_lag = True
    if use_pseudo_labeling:
        config.use_pseudo_labeling = True

    # ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ: Optuna íŠœë‹ ê²°ê³¼ ìë™ ì ìš© (--no-tuned-params ì‹œ ê±´ë„ˆëœ€)
    if not no_tuned_params:
        config.apply_tuned_params()

    print(f"\n{'â”'*60}")
    print(f"  ğŸš€ House Price Prediction â€” ì•™ìƒë¸” í•™ìŠµ íŒŒì´í”„ë¼ì¸")
    print(f"{'â”'*60}")

    # â”€â”€ ë°ì´í„° ë¡œë“œ â”€â”€
    X_train, y_train, X_test = _load_data(config)

    # â”€â”€ ì•™ìƒë¸” í•™ìŠµ â”€â”€
    ensemble_trainer = EnsembleTrainer(config)
    ensemble_result = ensemble_trainer.train_ensemble(X_train, y_train, X_test)

    # â”€â”€ Pseudo Labeling (Exp10) â”€â”€
    if config.use_pseudo_labeling and ensemble_result["ensemble_test_predictions"] is not None:
        ratio = config.pseudo_label_ratio
        n_pseudo = max(1, int(len(X_test) * ratio))
        pred_log = ensemble_result["ensemble_test_predictions"]
        median = np.median(pred_log)
        dist = np.abs(pred_log - median)
        idx = np.argsort(dist)[:n_pseudo]
        X_pseudo = X_test.iloc[idx].reset_index(drop=True)
        # ëª¨ë¸ì€ log1p(y) í•™ìŠµ â†’ pseudoë„ ì›ë³¸ ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜ (ë§Œì›)
        y_pseudo_original = np.expm1(pred_log[idx])
        y_pseudo = pd.Series(y_pseudo_original, index=X_pseudo.index)
        X_train_aug = pd.concat([X_train, X_pseudo], ignore_index=True)
        y_train_aug = pd.concat([y_train, y_pseudo], ignore_index=True)
        print(f"\n  ğŸ“Œ Pseudo Labeling: {n_pseudo}ê±´ ì¶”ê°€ í›„ ì¬í•™ìŠµ")
        ensemble_result = ensemble_trainer.train_ensemble(X_train_aug, y_train_aug, X_test)

    # â”€â”€ ê°œë³„ ëª¨ë¸ í”¼ì²˜ ì¤‘ìš”ë„ ì €ì¥ â”€â”€
    for model_name, result in ensemble_result["results"].items():
        if result.feature_importances is not None:
            imp_path = config.output_dir / f"feature_importance_{model_name}.csv"
            result.feature_importances.to_csv(imp_path, index=False)
            tqdm.write(f"  ğŸ’¾ í”¼ì²˜ ì¤‘ìš”ë„ ì €ì¥: {imp_path.name}")

    # â”€â”€ Submission ì €ì¥ â”€â”€
    if save_submission and ensemble_result["ensemble_test_predictions"] is not None:
        _save_submission(
            ensemble_result["ensemble_test_predictions"],
            config.output_dir,
            config.use_log_target,
            y_train=y_train.values if hasattr(y_train, "values") else y_train,
        )

    total_elapsed = time.time() - total_start
    print(f"\n  â±  ì „ì²´ ì†Œìš” ì‹œê°„: {total_elapsed:.1f}ì´ˆ ({total_elapsed / 60:.1f}ë¶„)")
    print(f"{'â”'*60}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ì•™ìƒë¸” í•™ìŠµ (LightGBM + XGBoost + CatBoost)")
    parser.add_argument("--n-splits", type=int, default=5, help="K-Fold ë¶„í•  ìˆ˜")
    parser.add_argument("--save-submission", action="store_true", help="submission.csv ì €ì¥")
    parser.add_argument(
        "--models",
        nargs="+",
        default=None,
        choices=["lightgbm", "lightgbm_quantile", "xgboost", "catboost", "mlp"],
        help="ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸: lightgbm, xgboost, catboost)",
    )
    parser.add_argument(
        "--stacking",
        action="store_true",
        help="Stacking ì•™ìƒë¸” ì‚¬ìš© (Ridge ë©”íƒ€ í•™ìŠµê¸°)",
    )
    parser.add_argument(
        "--multi-seed",
        action="store_true",
        help="Multi-seed ì•™ìƒë¸” ì‚¬ìš© (5ê°œ ì‹œë“œ í‰ê· )",
    )
    parser.add_argument(
        "--pseudo-labeling",
        action="store_true",
        help="Pseudo Labeling ì‚¬ìš© (í…ŒìŠ¤íŠ¸ ë°ì´í„° ë°˜ë³µ í•™ìŠµ)",
    )
    parser.add_argument(
        "--quantile",
        action="store_true",
        help="LightGBM Quantile Regression ëª¨ë¸ ì¶”ê°€",
    )
    parser.add_argument(
        "--mlp",
        action="store_true",
        help="MLP ì‹ ê²½ë§ ëª¨ë¸ ì¶”ê°€",
    )
    parser.add_argument(
        "--optimized",
        action="store_true",
        help="ìµœì í™” ëª¨ë“œ: multi-seed + stacking + time-lag í•œë²ˆì— í™œì„±í™”",
    )
    parser.add_argument(
        "--cv-strategy",
        type=str,
        default="kfold",
        choices=["kfold", "timeseries"],
        help="CV ì „ëµ (ê¸°ë³¸: kfold)",
    )
    parser.add_argument(
        "--no-tuned-params",
        action="store_true",
        help="Optuna íŠœë‹ íŒŒë¼ë¯¸í„° ë¯¸ì ìš©",
    )
    args = parser.parse_args()
    main(
        n_splits=args.n_splits,
        save_submission=args.save_submission,
        models=args.models,
        use_stacking=args.stacking,
        use_multi_seed=args.multi_seed,
        use_pseudo_labeling=args.pseudo_labeling,
        use_quantile=args.quantile,
        use_mlp=args.mlp,
        optimized=args.optimized,
        cv_strategy=args.cv_strategy,
        no_tuned_params=args.no_tuned_params,
    )
