# 전처리 파이프라인 상세 보고서 (Preprocessing Pipeline Detail)

본 문서는 서울 아파트 실거래가 예측을 위해 수행된 데이터 전처리 과정의 논리와 구현 방법을 상세히 기술합니다. 주피터 노트북의 각 단계별 설명으로 활용할 수 있습니다.

## 1. 데이터 정제 (Data Cleaning)

데이터의 품질을 높이기 위해 노이즈를 제거하고 유의미한 변수만 남기는 작업을 선행했습니다.

### 1-1. 행(Row) 필터링: 취소된 거래 제거

**문제**: 학습 데이터에는 거래가 취소된(`해제사유발생일` 존재) 기록이 포함되어 있습니다. 이는 시장의 정상적인 가격 정보가 아니며 모델에 노이즈를 유발합니다.
**해결**: `해제사유발생일` 컬럼에 값이 있는 행을 모두 삭제하였습니다. (단, Test 데이터는 평가를 위해 유지)

```python
# Code Concept
train = train[train['해제사유발생일'].isnull()]
```

### 1-2. 열(Column) 필터링: 불필요 변수 삭제

**문제**: 전체 데이터의 50% 이상이 결측치이거나, 가격 결정에 영향을 주지 않는 단순 행정 정보(예: 전화번호, 등기일자)가 다수 존재했습니다.
**해결**: 상관관계 분석과 결측률 확인을 통해 26개의 불투명한 변수를 제거하여 모델의 복잡도를 낮췄습니다.

* **제거된 주요 변수**: `거래유형`, `중개사소재지`, `k-전화번호`, `등기신청일자` 등

## 2. 좌표 복원 및 지오코딩 (Geocoding & Restoration)

본 프로젝트의 가장 핵심적인 전처리 단계로, 78%에 달하는 좌표(`좌표X/Y`) 결측치를 해결하기 위해 2단계 전략을 사용했습니다.

### 2-1. API 기반 지오코딩 (1차 복원)

결측된 주소(시군구 + 번지) 중 유니크한 주소 약 8,200개를 추출하여 지오코딩 API를 순차적으로 호출했습니다.

1. **Vworld API (국토교통부)**: 가장 정확한 지적도 기반 좌표 반환.
2. **Naver/Kakao API**: Vworld 실패 시 상업용 지도 데이터로 보완.
이 과정을 통해 약 98%의 주소를 좌표로 변환했습니다.

### 2-2. 공간 중앙값 대체 (2차 복원 및 이상치 처리)

API로도 찾을 수 없거나(폐지된 주소), 결과가 서울 범위를 벗어난 이상치(전북 익산 등 오매핑)가 약 3,000건 발생했습니다.
**해결 논리**: "동일한 법정동(Dong)에 위치한 아파트들은 지리적으로 인접해 있다"는 가정 하에 공간적 통계값을 활용했습니다.

1. **이상치 제거**: 위도/경도가 서울 경계를 벗어나면 `NaN` 처리.
2. **중앙값 주입**: 해당 아파트가 속한 **'동(Dong)'의 정상 좌표 중앙값(Median)** 으로 결측치를 채웠습니다.

```python
# Code Concept: 동별 중앙값으로 결측치 채우기
df['좌표X'] = df.groupby('Dong')['좌표X'].transform(lambda x: x.fillna(x.median()))
```

## 3. 결측치 예측 (Model-based Imputation)

변수의 특성에 따라 단순 평균이 아닌 예측 모델을 활용하여 데이터의 정합성을 높였습니다.

### 주차대수 복원 (RandomForest)

`주차대수`는 단지의 `전용면적`, `건축년도`, `위치(구)`에 따라 크게 달라집니다. 따라서 단순 평균 등으로 채울 경우 왜곡이 발생할 수 있습니다.
**해결**: 결측이 없는 데이터로 **RandomForest Regressor** 를 학습시켜, 결측된 `주차대수`를 예측하여 채워 넣었습니다. (R2 Score 약 0.86 달성)

## 4. 특성 공학 (Feature Engineering)

모델이 데이터를 더 잘 이해할 수 있도록 파생 변수를 생성하고 분포를 조정했습니다.

* **시계열 변수 (`days_since`)**: 날짜 형식(Date)을 모델이 바로 이해하기 어렵기 때문에, 기준일(2007-01-01)로부터 경과한 일수로 변환하여 선형적인 시간 추세를 학습하도록 했습니다.
* **브랜드 프리미엄 (`is_top_brand`)**: 아파트 이름에 10대 건설사 브랜드(래미안, 자이, 힐스테이트 등) 포함 여부를 0/1 바이너리 변수로 생성했습니다.
* **로그 변환 (Log Transformation)**: `실거래가(Target)`와 `전용면적`은 전형적인 오른쪽 꼬리가 긴(Right-skewed) 분포를 가집니다. 이를 `np.log1p`로 변환하여 정규분포에 가깝게 만듦으로써 선형 회귀 및 위상 기반 모델의 성능을 최적화했습니다.

## 5. 인코딩 전략 (Encoding Strategy)

범주형 변수의 특성에 맞춰 두 가지 인코딩 방식을 혼용했습니다.

### 5-1. 타겟 인코딩 (Target Encoding via K-Fold)

**대상**: `구(Gu)`, `동(Dong)`
**이유**: 범주(Category)의 개수가 너무 많아 원-핫 인코딩 시 차원이 폭발하며, 레이블 인코딩은 지역 간의 가격 차이를 반영하지 못합니다.
**방법**: 각 지역의 **'평균 실거래가'** 정보를 변수값으로 사용했습니다. 단, 과적합(Overfitting)을 방지하기 위해 데이터를 5개로 나누어(K-Fold) **"자신이 포함되지 않은 데이터의 평균"** 을 사용하는 방식을 적용했습니다.

### 5-2. 레이블 인코딩 (Label Encoding)

**대상**: `아파트`, `주상복합` 등 단지분류, 복도유형, 난방방식.
**이유**: 범주의 개수가 적고, 모델이 범주 간의 단순 구분을 학습하는 데 무리가 없으므로 간결한 레이블 인코딩을 적용했습니다.
